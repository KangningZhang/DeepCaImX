{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepCaImX introduction and guide\n",
    "## Import components: Keras, SciPy input/output, Numpy, Time, and Visualization with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcMM6MX34NY-"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import backend\n",
    "from keras.constraints import *\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up architecture of DeepCaImX, corresponding loss functions, and training methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hkHn42E_uo8"
   },
   "outputs": [],
   "source": [
    "class DeepCaImX():\n",
    "    def __init__(self):        \n",
    "        ########### Loss function for task segmentation and traces extraction ###########\n",
    "        self.N = 4\n",
    "        def denoise_loss(y_true, y_pred): # MSE with contraint\n",
    "            regularized_loss = backend.sum(backend.square(y_pred[:,:,:,:,0] - y_true[:,:,:,:,0])) + 0.01*backend.sum(backend.square(y_pred[:,:,:,:,5]))         \n",
    "            return regularized_loss/y_true.shape[1]\n",
    "        \n",
    "        def dice_coefficient(x1, x2):\n",
    "            smooth = 1e-6\n",
    "            intersection  = backend.sum(x1*x2)\n",
    "            union = backend.sum(x1+x2)\n",
    "            return (2.*intersection + smooth)/(union + smooth)\n",
    "        def seg_loss(y_true, y_pred):\n",
    "            smooth = 1e-6\n",
    "            attention_loss = 1 - dice_coefficient(y_pred[:,0:100,:,:,0], y_true[:,0:100,:,:,0])            \n",
    "            seg_loss = 1 - dice_coefficient(y_pred[:,100:104,:,:,0], y_true[:,100:104,:,:,0])\n",
    "            #diver_constraint = backend.mean(dice_coefficient(y_pred[:,100,:,:,0], y_pred[:,101,:,:,0]) + dice_coefficient(y_pred[:,100,:,:,0], y_pred[:,102,:,:,0]) + dice_coefficient(y_pred[:,100,:,:,0], y_pred[:,103,:,:,0]) + dice_coefficient(y_pred[:,101,:,:,0], y_pred[:,102,:,:,0] + dice_coefficient(y_pred[:,101,:,:,0], y_pred[:,103,:,:,0]) + dice_coefficient(y_pred[:,102,:,:,0], y_pred[:,103,:,:,0])))\n",
    "            \n",
    "            return 10*(0.1*attention_loss + 0.9*seg_loss)\n",
    "        \n",
    "        def trace_loss(y_true, y_pred):\n",
    "            smooth = 1e-6\n",
    "            y_true = y_true[:,2:98]\n",
    "            pearson_correlation_loss = (backend.sum((y_pred-backend.mean(y_pred))*(y_true-backend.mean(y_true)))+smooth) / (backend.sqrt((backend.sum(backend.square(y_pred-backend.mean(y_pred)))+smooth)*(backend.sum(backend.square((y_true-backend.mean(y_true))))+smooth)))\n",
    "            pearson_correlation_loss = 1 - pearson_correlation_loss\n",
    "            return 10*pearson_correlation_loss\n",
    "        ##################################################################################\n",
    "        \n",
    "        ###########                     Initialization                        ############\n",
    "        optimizer = Adam(learning_rate=1e-3)\n",
    "        self.DeepCaImX_model = self.DeepCaImX()\n",
    "        #self.DeepCaImX_model.summary()\n",
    "        \n",
    "        ##################################################################################\n",
    "        \n",
    "        ###########               Compiling multi-tasks model                  ###########\n",
    "        self.DeepCaImX_model.compile_metrics = None\n",
    "        self.DeepCaImX_model.compile(loss=[denoise_loss,seg_loss,trace_loss], optimizer=optimizer)\n",
    "        #self.DeepCaImX_model.compile(loss=[denoise_loss,seg_loss], optimizer=optimizer)\n",
    "        ##################################################################################\n",
    "    \n",
    "    \n",
    "    ###########                  Architecture of ISTA-Net                      ###########    \n",
    "    def DeepCaImX(self):\n",
    "        def ISTA_blocks(R):\n",
    "            temp = 0.01\n",
    "            N = self.N\n",
    "            conv_1 = Conv3D(N, (1,3,3), activation = None, padding = 'same', data_format='channels_last')(R)                \n",
    "            f1 = Conv3D(N, (1,3,3), activation = 'relu', padding = 'same', data_format='channels_last')\n",
    "            conv_2 = f1(conv_1)\n",
    "            conv_symm = f1(conv_1)\n",
    "            f2 = Conv3D(N, (1,3,3), activation = None, padding = 'same', data_format='channels_last')\n",
    "            conv_3 = f2(conv_2)\n",
    "            conv_symm = f2(conv_symm)\n",
    "            conv_4 = multiply([Lambda(lambda x: backend.sign(x))(conv_3), ReLU()(Lambda(lambda x: x-temp)(Lambda(lambda x: backend.abs(x))(conv_3)))])\n",
    "            f3 = Conv3D(N, (1,3,3), activation = 'relu', padding = 'same', data_format='channels_last')\n",
    "            conv_5 = f3(conv_4)\n",
    "            conv_symm = f3(conv_symm)\n",
    "            f4 = Conv3D(N, (1,3,3), activation = None, padding = 'same', data_format='channels_last')\n",
    "            conv_6 = f4(conv_5)       \n",
    "            conv_symm = f4(conv_symm)       \n",
    "            conv_7 = Conv3D(1, (1,3,3), activation = None, padding = 'same', data_format='channels_last')(conv_6)                \n",
    "            conv_7 = add([conv_7, R])\n",
    "            conv_8 = subtract([conv_symm, conv_1])\n",
    "            return conv_4, conv_7, conv_8\n",
    "        \n",
    "        \n",
    "            \n",
    "        def CFF (inputs):\n",
    "            def cnn_block(inputs,num_filters=self.N*8,kernel_size=(3,3,3),dilation_rate=(1,1,1),padding=\"same\",use_bias=False):\n",
    "                x = Conv3D(num_filters,kernel_size=kernel_size,dilation_rate=dilation_rate,padding=\"same\",use_bias=use_bias,kernel_initializer=keras.initializers.HeNormal())(inputs)\n",
    "                x = BatchNormalization()(x)\n",
    "                return ReLU()(x)\n",
    "\n",
    "            def DilatedSpatialPyramidPooling(inputs):\n",
    "                x = AveragePooling3D(pool_size=(1,8,8))(inputs)\n",
    "                x = cnn_block(x, kernel_size=1, use_bias=True)\n",
    "                out_pool = UpSampling3D(size=(1,8,8))(x)\n",
    "                out_1 = cnn_block(inputs, kernel_size=1, dilation_rate=(1,1,1))\n",
    "                out_3 = cnn_block(inputs, dilation_rate=(1,3,3))\n",
    "                out_6 = cnn_block(inputs, dilation_rate=(1,6,6))\n",
    "                out_9 = cnn_block(inputs, dilation_rate=(1,9,9))\n",
    "                x = Concatenate(axis=4)([out_pool, out_1, out_3, out_6, out_9])\n",
    "                output = cnn_block(x, kernel_size=1)\n",
    "                return output\n",
    "            def backbone_resnet(inputs):\n",
    "                conv1_1 = cnn_block(inputs,num_filters=self.N*2)\n",
    "                conv1_2 = cnn_block(conv1_1,num_filters=self.N*2)\n",
    "                conv1_3 = cnn_block(conv1_2,num_filters=self.N*2)\n",
    "                conv1_4 = ReLU()(add([conv1_3, conv1_1]))\n",
    "                pool1 = MaxPooling3D(pool_size=(1,2,2))(conv1_4)\n",
    "\n",
    "                conv2_1 = cnn_block(pool1,num_filters=self.N*4)\n",
    "                conv2_2 = cnn_block(conv2_1,num_filters=self.N*4)\n",
    "                conv2_3 = cnn_block(conv2_2,num_filters=self.N*4)\n",
    "                conv2_4 = ReLU()(add([conv2_3, conv2_1]))\n",
    "\n",
    "                conv3_1 = cnn_block(conv2_4,num_filters=self.N*4)\n",
    "                conv3_2 = cnn_block(conv3_1,num_filters=self.N*4)\n",
    "                conv3_3 = cnn_block(conv3_2,num_filters=self.N*4)\n",
    "                conv3_4 = ReLU()(add([conv3_3, conv3_1]))\n",
    "                output = AveragePooling3D(pool_size=(1,2,2))(conv3_4)\n",
    "                return pool1, output\n",
    "            \n",
    "            [input_2, feature] = backbone_resnet(inputs)\n",
    "            input_1 = DilatedSpatialPyramidPooling(feature)\n",
    "            input_1 = UpSampling3D(size=(1,2,2))(input_1)\n",
    "            input_2 = cnn_block(input_2, num_filters=self.N*4, kernel_size=1)\n",
    "\n",
    "            x = Concatenate(axis=4)([input_1, input_2])\n",
    "            x = cnn_block(x,num_filters=self.N*4)\n",
    "            x = cnn_block(x,num_filters=self.N*2)\n",
    "            x = UpSampling3D(size=(1,2,2))(x)\n",
    "            x = cnn_block(x,num_filters=self.N)\n",
    "            att = Conv3D(1,1,padding=\"same\",activation='tanh')(x)\n",
    "            att = ReLU()(att)\n",
    "            \n",
    "            seg = Permute((2,3,4,1))(att)\n",
    "            seg = Dense(64,'relu',use_bias=False)(seg)\n",
    "            seg = Dense(32,'relu',use_bias=False)(seg)\n",
    "            seg = Dense(16,'relu',use_bias=False)(seg)\n",
    "            seg = Dense(8,'relu',use_bias=False)(seg)\n",
    "            seg = Dense(self.N,'tanh',use_bias=False)(seg)            \n",
    "            seg = ReLU()(seg)\n",
    "            seg_ROI = Permute((4,1,2,3))(seg)\n",
    "            seg = tf.squeeze(seg, axis=3)\n",
    "            kernel = tf.ones((5,5,1))\n",
    "            seg_1 = Lambda(lambda x: x[:,:,:,0])(seg)\n",
    "            seg_1 = tf.expand_dims(seg_1, axis=3)\n",
    "            seg_1 = tf.nn.erosion2d(value=seg_1,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_1 = tf.nn.dilation2d(input=seg_1,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_2 = Lambda(lambda x: x[:,:,:,1])(seg)\n",
    "            seg_2 = tf.expand_dims(seg_2, axis=3)\n",
    "            seg_2 = tf.nn.erosion2d(value=seg_2,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_2 = tf.nn.dilation2d(input=seg_2,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_3 = Lambda(lambda x: x[:,:,:,2])(seg)\n",
    "            seg_3 = tf.expand_dims(seg_3, axis=3)\n",
    "            seg_3 = tf.nn.erosion2d(value=seg_3,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_3 = tf.nn.dilation2d(input=seg_3,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_4 = Lambda(lambda x: x[:,:,:,3])(seg)\n",
    "            seg_4 = tf.expand_dims(seg_4, axis=3)\n",
    "            seg_4 = tf.nn.erosion2d(value=seg_4,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_4 = tf.nn.dilation2d(input=seg_4,filters=kernel,strides=(1,1,1,1),padding='SAME',data_format='NHWC',dilations=(1,1,1,1))\n",
    "            seg_map = Concatenate(axis=3)([seg_1, seg_2, seg_3, seg_4])\n",
    "            seg_map = tf.expand_dims(seg_map, axis=3)\n",
    "            seg_map = Permute((4,1,2,3))(seg_map)\n",
    "            return att, seg_ROI, seg_map \n",
    "        \n",
    "        Inputs = Input(shape=(100,32,32,1))\n",
    "        ##################################################################################\n",
    "        \n",
    "        ###########                Architecture of ISTA-Net                    ###########\n",
    "        temp = 0.01\n",
    "        R1 = Inputs # r1\n",
    "        [_, conv1_7, conv1_8] = ISTA_blocks(R1)            \n",
    "        R2 = subtract([conv1_7, Lambda(lambda x: temp*x)(subtract([conv1_7,Inputs]))]) # r2\n",
    "        [_, conv2_7, conv2_8] = ISTA_blocks(R2)\n",
    "        R3 = subtract([conv2_7, Lambda(lambda x: temp*x)(subtract([conv2_7,Inputs]))]) # r3\n",
    "        [_, conv3_7, conv3_8] = ISTA_blocks(R3)\n",
    "        R4 = subtract([conv3_7, Lambda(lambda x: temp*x)(subtract([conv3_7,Inputs]))]) # r4\n",
    "        [_, conv4_7, conv4_8] = ISTA_blocks(R4)\n",
    "        R5 = subtract([conv4_7, Lambda(lambda x: temp*x)(subtract([conv4_7,Inputs]))]) # r5\n",
    "        [conv5_4, denoise, conv5_8] = ISTA_blocks(R5)\n",
    "        \n",
    "        output_symm = conv1_8\n",
    "        output_symm = Add()([output_symm, conv2_8])\n",
    "        output_symm = Add()([output_symm, conv3_8])\n",
    "        output_symm = Add()([output_symm, conv4_8])\n",
    "        output_symm = Add()([output_symm, conv5_8])\n",
    "        output_symm = Lambda(lambda x: backend.mean(x,axis=4,keepdims=True)/5)(output_symm)\n",
    "        Sparse_prepro = tf.math.abs(conv5_4)\n",
    "        Sparse_prepro = keras.activations.tanh(Sparse_prepro)        \n",
    "        ###################################################################################################################\n",
    "        \n",
    "        ###########  Architecture of 2D Convolutional LSTM for ROIs segmentation and sequential attention maps  ########### \n",
    "        Att = ConvLSTM2D(self.N,3,padding='same',return_sequences=True)(Sparse_prepro)\n",
    "        [Att, seg_ROI, seg_map] = CFF(Att)\n",
    "        Seg = Concatenate(axis = 1)([Att, seg_ROI, seg_map]) # Shape: (?,100+4,32,32,1)\n",
    "        \n",
    "        ###################################################################################################################\n",
    "        \n",
    "        ###########           Architecture of 1D Convolutional layers for traces demixing and denoising         ###########\n",
    "        seg_map = Permute((4,2,3,1))(seg_ROI)  \n",
    "        video = multiply([Sparse_prepro, Att])\n",
    "        trace = multiply([video, seg_map])\n",
    "        trace = TimeDistributed(GlobalAveragePooling2D ())(trace) \n",
    "        trace = Conv1D(16,3,activation='relu', padding='valid',use_bias=False)(trace)\n",
    "        trace = Conv1D(8,3,activation='relu', padding='valid',use_bias=False)(trace)\n",
    "        trace = Conv1D(self.N,1,activation='relu', padding='valid',use_bias=False)(trace) # (?,96,4)\n",
    "        Denoise = Concatenate(axis = 4)([denoise, Sparse_prepro, output_symm]) # Shape: (?,100,64,64,1+4+1+1)\n",
    "        print('****************denoise*****************',Denoise)\n",
    "        print('****************segmentation*****************',Seg)\n",
    "        print('****************trace*****************',trace)\n",
    "        return Model(inputs = Inputs, outputs = [Denoise, Seg, trace])\n",
    "    ###################################################################################################################        \n",
    "    \n",
    "    \n",
    "    ###########               Define training methods of ROIs segmentation and traces extraction            ###########\n",
    "    def train(self, video, data, seg_GT, trace_GT, epoch, N_epoch, iteration, batch_size):\n",
    "        # Size of \"video\", \"data\" and \"att_GT\" is (?,100,32,32,1)\n",
    "        # Size of \"seg_GT\" is (?,32,32,4)\n",
    "        # Size of \"trace_GT\" is (?,100,4)\n",
    "        start_time = time.time()\n",
    "        video = np.float32(video)\n",
    "        seg_GT = np.float32(seg_GT)\n",
    "        trace_GT = np.float32(trace_GT)\n",
    "        att_GT = np.float32(np.zeros_like(data))\n",
    "        for k in range(trace_GT.shape[0]):\n",
    "            for i in range(trace_GT.shape[1]):\n",
    "                for j in range(seg_GT.shape[3]):\n",
    "                    att_GT[k,i,:,:,0] = att_GT[k,i,:,:,0] + seg_GT[k,:,:,j]*trace_GT[k,i,j]                \n",
    "        att_GT[att_GT>=0.05] = 1\n",
    "        att_GT[att_GT<0.05] = 0\n",
    "        \n",
    "        seg_GT = np.transpose(seg_GT,[0,3,1,2])\n",
    "        seg_GT = np.expand_dims(seg_GT,axis=4)\n",
    "        seg_GT = np.append(att_GT,seg_GT,axis=1)\n",
    "        loss = self.DeepCaImX_model.train_on_batch(video,[data,seg_GT,trace_GT])\n",
    "        print('Epoch: ',epoch+1, '/',int(N_epoch),' Iteration: ', iteration+1, '/', int(500/batch_size),', Loss_denoise: ',\"{:.4f}\".format(loss[1]),', Loss_seg: ',\"{:.4f}\".format(loss[2]),', Loss_trace: ',\"{:.4f}\".format(loss[3]))        \n",
    "        \n",
    "        if (iteration+1) % int(500/batch_size) == 0:\n",
    "            [img, seg, trace] = self.DeepCaImX_model.predict_on_batch(np.expand_dims(video[0], axis=0))\n",
    "            img_denoised = img[0,:,:,:,0]\n",
    "            img_sparse = img[0,:,:,:,1:5]\n",
    "            img_sparse = np.amax(img_sparse,axis=3)\n",
    "            img_GT = data[0,:,:,:,0]\n",
    "            img_raw = video[0,:,:,:,0]\n",
    "            att = seg[0,0:400,:,:,0]\n",
    "            att_GT = att_GT[0,:,:,:,0]\n",
    "            \n",
    "            plt.figure(figsize=(9,12))\n",
    "            plt.subplot(6,4,1)\n",
    "            plt.imshow(img_raw[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Raw 1')\n",
    "            plt.subplot(6,4,2)\n",
    "            plt.imshow(img_raw[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Raw 2')\n",
    "            plt.subplot(6,4,3)\n",
    "            plt.imshow(img_raw[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Raw 3')\n",
    "            plt.subplot(6,4,4)\n",
    "            plt.imshow(np.amax(img_raw,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Raw MIP')\n",
    "            \n",
    "            plt.subplot(6,4,5)\n",
    "            plt.imshow(img_GT[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Ground Truth 1')\n",
    "            plt.subplot(6,4,6)\n",
    "            plt.imshow(img_GT[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Ground Truth 2')\n",
    "            plt.subplot(6,4,7)\n",
    "            plt.imshow(img_GT[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Ground Truth 3')\n",
    "            plt.subplot(6,4,8)\n",
    "            plt.imshow(np.amax(img_GT,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Ground Truth MIP')\n",
    "            \n",
    "            plt.subplot(6,4,9)\n",
    "            plt.imshow(img_denoised[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Denoised Video 1')\n",
    "            plt.subplot(6,4,10)\n",
    "            plt.imshow(img_denoised[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Denoised Video 2')\n",
    "            plt.subplot(6,4,11)\n",
    "            plt.imshow(img_denoised[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Denoised Video 3')\n",
    "            plt.subplot(6,4,12)\n",
    "            plt.imshow(np.amax(img_denoised,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Denoised Video MIP')\n",
    "\n",
    "            plt.subplot(6,4,13)\n",
    "            plt.imshow(img_sparse[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Prepro Sparsity 1')\n",
    "            plt.subplot(6,4,14)\n",
    "            plt.imshow(img_sparse[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Prepro Sparsity 2')\n",
    "            plt.subplot(6,4,15)\n",
    "            plt.imshow(img_sparse[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Prepro Sparsity 3')\n",
    "            plt.subplot(6,4,16)\n",
    "            plt.imshow(np.amax(img_sparse,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Prepro Sparsity MIP')\n",
    "            \n",
    "            plt.subplot(6,4,17)\n",
    "            plt.imshow(att[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention Maps 1')\n",
    "            plt.subplot(6,4,18)\n",
    "            plt.imshow(att[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention Maps 2')\n",
    "            plt.subplot(6,4,19)\n",
    "            plt.imshow(att[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention Maps 3')\n",
    "            plt.subplot(6,4,20)\n",
    "            plt.imshow(np.amax(att,axis=0,keepdims=False),vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention Maps MIP')\n",
    "            \n",
    "            plt.subplot(6,4,21)\n",
    "            plt.imshow(att_GT[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention GT 1')\n",
    "            plt.subplot(6,4,22)\n",
    "            plt.imshow(att_GT[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention GT 2')\n",
    "            plt.subplot(6,4,23)\n",
    "            plt.imshow(att_GT[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention GT 3')\n",
    "            plt.subplot(6,4,24)\n",
    "            plt.imshow(np.amax(att_GT,axis=0,keepdims=False),vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.title('Attention GT MIP')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure(figsize=(8,4))\n",
    "            for i in range(4):\n",
    "                plt.subplot(2,4,i+1)                \n",
    "                plt.imshow(seg[0,104+i,:,:,0],vmin=0,vmax=1,cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title('Seg #'+str(i+1))\n",
    "                plt.subplot(2,4,i+5)\n",
    "                plt.imshow(seg_GT[0,100+i,:,:,0],vmin=0,vmax=1,cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title('GT #'+str(i+1))\n",
    "            plt.suptitle('Segmentation results')\n",
    "            plt.show()\n",
    "            trace = np.squeeze(trace[0])\n",
    "            trace = trace/(np.amax(trace)+1e-3)\n",
    "            trace_GT = np.squeeze(trace_GT[0])\n",
    "            plt.figure(figsize=(8,4))\n",
    "            for i in range(4):\n",
    "                plt.title('#'+str(i+1))\n",
    "                plt.subplot(2,4,i+1)\n",
    "                plt.plot(trace[:,i])\n",
    "                plt.ylim(0,1)\n",
    "                plt.axis('off')                \n",
    "                plt.subplot(2,4,i+5)\n",
    "                plt.plot(trace_GT[:,i])\n",
    "                plt.ylim(0,1)\n",
    "                plt.axis('off')\n",
    "            plt.suptitle('Traces results')\n",
    "            plt.show()\n",
    "            \n",
    "            del(seg)\n",
    "            del(seg_GT)\n",
    "            del(att_GT)\n",
    "            del(att)\n",
    "            del(img)\n",
    "            del(img_GT)\n",
    "            del(img_raw)\n",
    "            del(img_denoised)\n",
    "            del(img_sparse)\n",
    "            del(trace_GT)\n",
    "            del(trace)\n",
    "            self.DeepCaImX_model.save('./Pretrained Model/DeepCaImX_model_v1.h5')\n",
    "        \n",
    "        print(\"--- %s seconds escaped ---\" % (time.time() - start_time))\n",
    "        return loss\n",
    "    ###################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training dataset, set number of epoch and batch size, and train DeepCaImX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Allocate GPU memory in real-time\n",
    "config=tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "\n",
    "N_epoch = 200\n",
    "batch_size = 2\n",
    "\n",
    "model = DeepCaImX()\n",
    "loss_history = []\n",
    "start_time_total = time.time()\n",
    "for i in range(N_epoch): # epoch\n",
    "    index = np.random.permutation(500) + 1 # We will train 500 samples in total\n",
    "    start_time = time.time()\n",
    "    for j in range(int(500/batch_size)): # iteration\n",
    "        index_batch = index[j*batch_size:(j+1)*batch_size]\n",
    "        LSTM_Video = sio.loadmat('./Training Dataset/LSTM_Video_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Video = LSTM_Video['LSTM_video']\n",
    "        LSTM_Video = np.transpose(LSTM_Video,[2,0,1])\n",
    "        LSTM_Video = np.expand_dims(np.expand_dims(LSTM_Video,3),0)\n",
    "\n",
    "        LSTM_Data = sio.loadmat('./Training Dataset/LSTM_Data_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Data = LSTM_Data['LSTM_data']\n",
    "        LSTM_Data = np.transpose(LSTM_Data,[2,0,1])\n",
    "        LSTM_Data = np.expand_dims(np.expand_dims(LSTM_Data,3),0)\n",
    "\n",
    "        LSTM_Masks = sio.loadmat('./Training Dataset/LSTM_Masks_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Masks = LSTM_Masks['LSTM_mask']\n",
    "        LSTM_Masks = np.float32(np.expand_dims(LSTM_Masks,0))\n",
    "\n",
    "        LSTM_Trace = sio.loadmat('./Training Dataset/LSTM_Trace_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Trace = LSTM_Trace['LSTM_trace']\n",
    "        LSTM_Trace = np.transpose(LSTM_Trace,[1,0])\n",
    "        LSTM_Trace = np.expand_dims(LSTM_Trace,0)\n",
    "\n",
    "\n",
    "        for k in range(batch_size-1): # load in batchsize\n",
    "            Video = sio.loadmat('./Training Dataset/LSTM_Video_'+str(index_batch[k+1])+'.mat')\n",
    "            Video = Video['LSTM_video']\n",
    "            Video = np.transpose(Video,[2,0,1])\n",
    "            LSTM_Video = np.append(LSTM_Video, np.expand_dims(np.expand_dims(Video,3),0), axis = 0)\n",
    "\n",
    "            Data = sio.loadmat('./Training Dataset/LSTM_Data_'+str(index_batch[k+1])+'.mat')\n",
    "            Data = Data['LSTM_data']\n",
    "            Data = np.transpose(Data,[2,0,1])\n",
    "            LSTM_Data = np.append(LSTM_Data, np.expand_dims(np.expand_dims(Data,3),0), axis = 0)\n",
    "            \n",
    "            Masks = sio.loadmat('./Training Dataset/LSTM_Masks_'+str(index_batch[k+1])+'.mat')\n",
    "            Masks = np.float32(Masks['LSTM_mask'])\n",
    "            LSTM_Masks = np.append(LSTM_Masks, np.expand_dims(Masks,0), axis = 0)\n",
    "\n",
    "            Trace = sio.loadmat('./Training Dataset/LSTM_Trace_'+str(index_batch[k+1])+'.mat')\n",
    "            Trace = Trace['LSTM_trace']\n",
    "            Trace = np.transpose(Trace,[1,0])\n",
    "            LSTM_Trace = np.append(LSTM_Trace, np.expand_dims(Trace,0), axis = 0)\n",
    "            \n",
    "            del(Video)\n",
    "            del(Masks)\n",
    "            del(Trace)\n",
    "            del(Data)\n",
    "    \n",
    "        loss = model.train(LSTM_Video, LSTM_Data, LSTM_Masks, LSTM_Trace, i, N_epoch, j, batch_size)\n",
    "        loss_history.append(loss)\n",
    "        del(LSTM_Video)\n",
    "        del(LSTM_Data)\n",
    "        del(LSTM_Masks)\n",
    "        del(LSTM_Trace)\n",
    "    print(\"\\x1b[31m--- %s minutes escaped for this epoch ---\\x1b[0m\" % ((time.time() - start_time)/60))\n",
    "    # (Optional) The code below is used to measure the GPU memory occupied\n",
    "    #print(\"\\x1b[31m--- Current GPU Memory usage is: %s Gb ---\\x1b[0m\" % ((tf.config.experimental.get_memory_info('GPU:0')['current'])/1024/1024))\n",
    "    print()\n",
    "print(\"\\x1b[31m--- %s hours escaped for training ---\\x1b[0m\" % ((time.time() - start_time_total)/3600))        \n",
    "#sio.savemat('loss_history.mat',{'loss_history': np.array(loss_history)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained DeepCaImX model, set number of epoch and batch size, and give a further training on DeepCaImX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import backend\n",
    "from keras.constraints import *\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(DeepCaImX_model, video, data, seg_GT, trace_GT, epoch, N_epoch, iteration, batch_size):\n",
    "    # Size of \"video\", \"data\" and \"att_GT\" is (?,100,32,32,1)\n",
    "    # Size of \"seg_GT\" is (?,32,32,4)\n",
    "    # Size of \"trace_GT\" is (?,100,4)\n",
    "    start_time = time.time()\n",
    "    video = np.float32(video)\n",
    "    seg_GT = np.float32(seg_GT)\n",
    "    trace_GT = np.float32(trace_GT)\n",
    "    att_GT = np.float32(np.zeros_like(data))\n",
    "    for k in range(trace_GT.shape[0]):\n",
    "        for i in range(trace_GT.shape[1]):\n",
    "            for j in range(seg_GT.shape[3]):\n",
    "                att_GT[k,i,:,:,0] = att_GT[k,i,:,:,0] + seg_GT[k,:,:,j]*trace_GT[k,i,j]                \n",
    "    att_GT[att_GT>=0.05] = 1\n",
    "    att_GT[att_GT<0.05] = 0\n",
    "\n",
    "    seg_GT = np.transpose(seg_GT,[0,3,1,2])\n",
    "    seg_GT = np.expand_dims(seg_GT,axis=4)\n",
    "    seg_GT = np.append(att_GT,seg_GT,axis=1)\n",
    "    loss = DeepCaImX_model.train_on_batch(video,[data,seg_GT,trace_GT])\n",
    "    print('Epoch: ',epoch+1, '/',int(N_epoch),' Iteration: ', iteration+1, '/', int(500/batch_size),', Loss_denoise: ',\"{:.4f}\".format(loss[1]),', Loss_seg: ',\"{:.4f}\".format(loss[2]),', Loss_trace: ',\"{:.4f}\".format(loss[3]))        \n",
    "\n",
    "    if (iteration+1) % int(500/batch_size) == 0:\n",
    "        [img, seg, trace] = DeepCaImX_model.predict_on_batch(np.expand_dims(video[0], axis=0))\n",
    "        img_denoised = img[0,:,:,:,0]\n",
    "        img_sparse = img[0,:,:,:,1:5]\n",
    "        img_sparse = np.amax(img_sparse,axis=3)\n",
    "        img_GT = data[0,:,:,:,0]\n",
    "        img_raw = video[0,:,:,:,0]\n",
    "        att = seg[0,0:400,:,:,0]\n",
    "        att_GT = att_GT[0,:,:,:,0]\n",
    "\n",
    "        plt.figure(figsize=(9,12))\n",
    "        plt.subplot(6,4,1)\n",
    "        plt.imshow(img_raw[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Raw 1')\n",
    "        plt.subplot(6,4,2)\n",
    "        plt.imshow(img_raw[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Raw 2')\n",
    "        plt.subplot(6,4,3)\n",
    "        plt.imshow(img_raw[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Raw 3')\n",
    "        plt.subplot(6,4,4)\n",
    "        plt.imshow(np.amax(img_raw,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Raw MIP')\n",
    "\n",
    "        plt.subplot(6,4,5)\n",
    "        plt.imshow(img_GT[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Ground Truth 1')\n",
    "        plt.subplot(6,4,6)\n",
    "        plt.imshow(img_GT[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Ground Truth 2')\n",
    "        plt.subplot(6,4,7)\n",
    "        plt.imshow(img_GT[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Ground Truth 3')\n",
    "        plt.subplot(6,4,8)\n",
    "        plt.imshow(np.amax(img_GT,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Ground Truth MIP')\n",
    "\n",
    "        plt.subplot(6,4,9)\n",
    "        plt.imshow(img_denoised[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Denoised Video 1')\n",
    "        plt.subplot(6,4,10)\n",
    "        plt.imshow(img_denoised[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Denoised Video 2')\n",
    "        plt.subplot(6,4,11)\n",
    "        plt.imshow(img_denoised[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Denoised Video 3')\n",
    "        plt.subplot(6,4,12)\n",
    "        plt.imshow(np.amax(img_denoised,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Denoised Video MIP')\n",
    "\n",
    "        plt.subplot(6,4,13)\n",
    "        plt.imshow(img_sparse[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Prepro Sparsity 1')\n",
    "        plt.subplot(6,4,14)\n",
    "        plt.imshow(img_sparse[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Prepro Sparsity 2')\n",
    "        plt.subplot(6,4,15)\n",
    "        plt.imshow(img_sparse[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Prepro Sparsity 3')\n",
    "        plt.subplot(6,4,16)\n",
    "        plt.imshow(np.amax(img_sparse,axis=0),vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Prepro Sparsity MIP')\n",
    "\n",
    "        plt.subplot(6,4,17)\n",
    "        plt.imshow(att[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention Maps 1')\n",
    "        plt.subplot(6,4,18)\n",
    "        plt.imshow(att[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention Maps 2')\n",
    "        plt.subplot(6,4,19)\n",
    "        plt.imshow(att[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention Maps 3')\n",
    "        plt.subplot(6,4,20)\n",
    "        plt.imshow(np.amax(att,axis=0,keepdims=False),vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention Maps MIP')\n",
    "\n",
    "        plt.subplot(6,4,21)\n",
    "        plt.imshow(att_GT[25,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention GT 1')\n",
    "        plt.subplot(6,4,22)\n",
    "        plt.imshow(att_GT[50,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention GT 2')\n",
    "        plt.subplot(6,4,23)\n",
    "        plt.imshow(att_GT[75,:,:],vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention GT 3')\n",
    "        plt.subplot(6,4,24)\n",
    "        plt.imshow(np.amax(att_GT,axis=0,keepdims=False),vmin=0,vmax=1,cmap='gray')\n",
    "        plt.axis('off')  \n",
    "        plt.title('Attention GT MIP')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(8,4))\n",
    "        for i in range(4):\n",
    "            plt.subplot(2,4,i+1)                \n",
    "            plt.imshow(seg[0,104+i,:,:,0],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Seg #'+str(i+1))\n",
    "            plt.subplot(2,4,i+5)\n",
    "            plt.imshow(seg_GT[0,100+i,:,:,0],vmin=0,vmax=1,cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('GT #'+str(i+1))\n",
    "        plt.suptitle('Segmentation results')\n",
    "        plt.show()\n",
    "        trace = np.squeeze(trace[0])\n",
    "        trace = trace/(np.amax(trace)+1e-3)\n",
    "        trace_GT = np.squeeze(trace_GT[0])\n",
    "        plt.figure(figsize=(8,4))\n",
    "        for i in range(4):\n",
    "            plt.title('#'+str(i+1))\n",
    "            plt.subplot(2,4,i+1)\n",
    "            plt.plot(trace[:,i])\n",
    "            plt.ylim(0,1)\n",
    "            plt.axis('off')                \n",
    "            plt.subplot(2,4,i+5)\n",
    "            plt.plot(trace_GT[:,i])\n",
    "            plt.ylim(0,1)\n",
    "            plt.axis('off')\n",
    "        plt.suptitle('Traces results')\n",
    "        plt.show()\n",
    "\n",
    "        del(seg)\n",
    "        del(seg_GT)\n",
    "        del(att_GT)\n",
    "        del(att)\n",
    "        del(img)\n",
    "        del(img_GT)\n",
    "        del(img_raw)\n",
    "        del(img_denoised)\n",
    "        del(img_sparse)\n",
    "        del(trace_GT)\n",
    "        del(trace)\n",
    "        DeepCaImX_model.save('./Pretrained Model/DeepCaImX_model_v2.h5')\n",
    "\n",
    "    print(\"--- %s seconds escaped ---\" % (time.time() - start_time))\n",
    "    return loss, DeepCaImX_model\n",
    "    ###################################################################################################################\n",
    "    \n",
    "def denoise_loss(y_true, y_pred): # MSE with contraint\n",
    "    regularized_loss = backend.sum(backend.square(y_pred[:,:,:,:,0] - y_true[:,:,:,:,0])) + 0.01*backend.sum(backend.square(y_pred[:,:,:,:,5]))         \n",
    "    return regularized_loss/y_true.shape[1]\n",
    "\n",
    "def dice_coefficient(x1, x2):\n",
    "    smooth = 1e-6\n",
    "    intersection  = backend.sum(x1*x2)\n",
    "    union = backend.sum(x1+x2)\n",
    "    return (2.*intersection + smooth)/(union + smooth)\n",
    "def seg_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    attention_loss = 1 - dice_coefficient(y_pred[:,0:100,:,:,0], y_true[:,0:100,:,:,0])            \n",
    "    seg_loss = 1 - dice_coefficient(y_pred[:,100:104,:,:,0], y_true[:,100:104,:,:,0])\n",
    "    return 10*(0.1*attention_loss + 0.9*seg_loss)\n",
    "\n",
    "def trace_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = y_true[:,2:98]\n",
    "    pearson_correlation_loss = (backend.sum((y_pred-backend.mean(y_pred))*(y_true-backend.mean(y_true)))+smooth) / (backend.sqrt((backend.sum(backend.square(y_pred-backend.mean(y_pred)))+smooth)*(backend.sum(backend.square((y_true-backend.mean(y_true))))+smooth)))\n",
    "    pearson_correlation_loss = 1 - pearson_correlation_loss\n",
    "    return 10*pearson_correlation_loss\n",
    "\n",
    "## Allocate GPU memory in real-time\n",
    "config=tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "\n",
    "N_epoch = 200\n",
    "batch_size = 2\n",
    "model = load_model('./Pretrained Model/DeepCaImX_model_v1.h5',custom_objects={'backend': backend,'dice_coefficient': dice_coefficient,'denoise_loss': denoise_loss,'seg_loss': seg_loss,'trace_loss': trace_loss})        \n",
    "model.summary()\n",
    "loss_history = []\n",
    "start_time_total = time.time()\n",
    "t = 0\n",
    "for i in range(N_epoch): # epoch    \n",
    "    index = np.random.permutation(500) + 1 # We will train 500 samples in total\n",
    "    start_time = time.time()\n",
    "    for j in range(int(500/batch_size)): # iteration\n",
    "        index_batch = index[j*batch_size:(j+1)*batch_size]\n",
    "        LSTM_Video = sio.loadmat('./Training Dataset/LSTM_Video_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Video = LSTM_Video['LSTM_video']\n",
    "        LSTM_Video = np.transpose(LSTM_Video,[2,0,1])\n",
    "        LSTM_Video = np.expand_dims(np.expand_dims(LSTM_Video,3),0)\n",
    "\n",
    "        LSTM_Data = sio.loadmat('./Training Dataset/LSTM_Data_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Data = LSTM_Data['LSTM_data']\n",
    "        LSTM_Data = np.transpose(LSTM_Data,[2,0,1])\n",
    "        LSTM_Data = np.expand_dims(np.expand_dims(LSTM_Data,3),0)\n",
    "\n",
    "        LSTM_Masks = sio.loadmat('./Training Dataset/LSTM_Masks_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Masks = LSTM_Masks['LSTM_mask']\n",
    "        LSTM_Masks = np.float32(np.expand_dims(LSTM_Masks,0))\n",
    "\n",
    "        LSTM_Trace = sio.loadmat('./Training Dataset/LSTM_Trace_'+str(index_batch[0])+'.mat')\n",
    "        LSTM_Trace = LSTM_Trace['LSTM_trace']\n",
    "        LSTM_Trace = np.transpose(LSTM_Trace,[1,0])\n",
    "        LSTM_Trace = np.expand_dims(LSTM_Trace,0)\n",
    "\n",
    "\n",
    "        for k in range(batch_size-1): # load in batchsize\n",
    "            Video = sio.loadmat('./Training Dataset/LSTM_Video_'+str(index_batch[k+1])+'.mat')\n",
    "            Video = Video['LSTM_video']\n",
    "            Video = np.transpose(Video,[2,0,1])\n",
    "            LSTM_Video = np.append(LSTM_Video, np.expand_dims(np.expand_dims(Video,3),0), axis = 0)\n",
    "\n",
    "            Data = sio.loadmat('./Training Dataset/LSTM_Data_'+str(index_batch[k+1])+'.mat')\n",
    "            Data = Data['LSTM_data']\n",
    "            Data = np.transpose(Data,[2,0,1])\n",
    "            LSTM_Data = np.append(LSTM_Data, np.expand_dims(np.expand_dims(Data,3),0), axis = 0)\n",
    "            \n",
    "            Masks = sio.loadmat('./Training Dataset/LSTM_Masks_'+str(index_batch[k+1])+'.mat')\n",
    "            Masks = np.float32(Masks['LSTM_mask'])\n",
    "            LSTM_Masks = np.append(LSTM_Masks, np.expand_dims(Masks,0), axis = 0)\n",
    "\n",
    "            Trace = sio.loadmat('./Training Dataset/LSTM_Trace_'+str(index_batch[k+1])+'.mat')\n",
    "            Trace = Trace['LSTM_trace']\n",
    "            Trace = np.transpose(Trace,[1,0])\n",
    "            LSTM_Trace = np.append(LSTM_Trace, np.expand_dims(Trace,0), axis = 0)\n",
    "            \n",
    "            del(Video)\n",
    "            del(Masks)\n",
    "            del(Trace)\n",
    "            del(Data)\n",
    "    \n",
    "        [loss, model] = train(model, LSTM_Video, LSTM_Data, LSTM_Masks, LSTM_Trace, i, N_epoch, j, batch_size)\n",
    "        loss_history.append(loss)\n",
    "        del(LSTM_Video)\n",
    "        del(LSTM_Data)\n",
    "        del(LSTM_Masks)\n",
    "        del(LSTM_Trace)\n",
    "    print(\"\\x1b[31m--- %s minutes escaped for this epoch ---\\x1b[0m\" % ((time.time() - start_time)/60))\n",
    "    # (Optional) The code below is used to measure the GPU memory occupied \n",
    "    #print(\"\\x1b[31m--- Current GPU Memory usage is: %s GB ---\\x1b[0m\" % ((tf.config.experimental.get_memory_info('GPU:0')['current'])/1024/1024))\n",
    "    print()\n",
    "print(\"\\x1b[31m--- %s hours escaped for training ---\\x1b[0m\" % ((time.time() - start_time_total)/3600))        \n",
    "#sio.savemat('loss_history.mat',{'loss_history': np.array(loss_history)})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow2.9_Kangning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
